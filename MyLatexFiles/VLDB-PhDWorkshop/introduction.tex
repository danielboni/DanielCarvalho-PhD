In recent years, the cloud has been the most popular deployment environment for data integration~\cite{Carvalho2015}.
Data integration has evolved with the emergence of data services that deliver data under different quality conditions related to data freshness, cost, reliability, availability, among others. 
%
However, the lack of an associated meta-data describing the data, currently produced in huge quantities, makes the integration process more challenging. 
%Data are produced continuously and on demand in huge quantities and sometimes with few associated meta-data, which makes the integration process more challenging. 
%
Data integration in service-oriented architectures can be seen as a service composition problem in which given a query the objective is to lookup and compose data services that can contribute to produce a result~\cite{Benslimane:2013, Correndo2010, ElSheikh2013, Tian2010, YauY08}. 
%Some approaches express data integration as a service composition problem in which given a query the objective is to lookup and compose data services that can contribute to produce a result~\cite{Benslimane:2013}. 
%
%Finding the best service composition that can answer a query can be computationally costly. Furthermore,  executing the composition can lead to retrieve and process data collections that can require important memory, storage and computing resources.

%Data integration has been addressed in the service-oriented architectures~\cite{Correndo2010,ElSheikh2013,Tian2010,YauY08}. 
\cite{Benslimane:2013} described their approach for modeling, discovering, selecting and composing data services while enforcing providers' privacy and security policies.
\cite{Correndo2010} proposed a rewriting method based on SPARQL for RDF data integration. The work focused on avoiding ineffective data integration by solving the entity co-reference problem. \cite{ElSheikh2013} introduced SODIM, a system which combines data integration, service-oriented architecture and MapReduce distributed processing. \cite{YauY08} presented a solution focusing on data privacy in order to integrate data. \cite{Tian2010} developed an inter-cloud data integration system that considers a trade-off between users' privacy requirements and the cost for protecting and processing data. According to the users' requirements, the query is created and executed meeting privacy and cost constraints. 
%
The novelty of these approaches is that they perform data integration in service-oriented and cloud contexts, particularly considering data services. They also take into consideration the requirement of computing resources for integrating data. Thus, they exploit parallel settings for implementing costly data integration processes. They are mainly focused on performance and privacy aspects putting aside other users' integration requirements such as data provenance, data integrity, confidentiality, reliability, availability, whether she wants to use free services, how much she is ready to pay for the integration, among others. 
%
Moreover, even with the cloud on-demand resources provisioning (which implies an  associated cost), the user is limited to her cloud subscription and maximum budget she is ready to pay for her desired integration. 
%The economic cost should be taken into consideration.

In cloud computing, the quality conditions under which services are delivered to users are agreed in contracts called service level agreements (SLA). We strongly believe that SLAs can be re-modeled in order (i) to cover the limitations regarding the users' integration requirements (including quality constraints and data requirements); and (ii) to enhance the quality in the current data integration solutions. 
%
Works on SLA in cloud computing mainly concern (i) the \textit{negotiation} of contracts between customers and providers; and (ii) \textit{monitoring} of cloud resources to detect SLA violations.
%Yet, to the best of our knowledge, we have not find works proposing SLA-based approach for data integration in a multi-cloud environment. 
Yet, to the best of our knowledge, few works considers SLAs in order to guide the entire data integration in multi-cloud environments.
Similarly to our idea, \cite{Nie07} proposed a SLA-based data integration model for grid environments. The approach uses SLAs to define database resources and evaluated them in terms of processing cost, amount of data and price of using the grid. In addition, a matching algorithm is proposed to produce query plans using the selected resources. 

%The most appropriated solutions based on these QoS are selected as final results. Our work differs from \cite{Nie07} in some aspects: 
%\begin{itemize}
%\item Data is delivered as \textit{data services} in a multi-cloud context. \textit{Data services} and \textit{cloud providers} export their SLA defining the quality conditions under which the service is delivered.
%\item SLAs are not limited only to describe the cost and amount of data, but also data quality aspects such its provenance, privacy, confidentiality, freshness, and service's delivery aspects such as response time, availability, reliability, among others.
%\item Users are able to express queries associating quality integration requirements to them. Then, the service selection and rewriting process in terms of service compositions are guided by the user's requirements and the SLAs exported by \textit{data services} and \textit{cloud providers}.
%\end{itemize}

In multi-cloud context, current SLA models are not sufficient to cover the data integration requirements. Thus, we are working on new models to include users' integration requirements concerning data requirements and quality constraints. In summary, the objectives of this PhD project contribute as following: (1) design of SLA model for data integration; (2) propose of a data integration approach adapted to the vision of the economic model of the cloud. The originality of our approach consists in guiding the entire data integration solution taking into account (i) user preferences statements; (ii) SLA contracts exported by different cloud providers; and (iii) several QoS measures associated to data collections properties (for instance, trust, privacy, economic cost); and (3) validation of our approach in a multi-cloud scenario.
